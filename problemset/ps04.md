# ps04
## 哈希表增长的一点讨论
在[[lec09 - Table Doubling, Karp-Rabin |lec09]]中已经讨论过两种hash表增长策略：
- 以m+1方式增长，append的均摊时间复杂度为$O(n)$
- 以2\*m的方式增长，append的均摊时间复杂度为$O(1)$。

如果以m+k的方式增长，append的均摊时间复杂度为$O(n/k)$。m+1增长策略是m+k增长策略的特例。
## Python的dictionary
pset中提供了[python设计分析](http://svn.python.org/projects/python/trunk/Objects/dictnotes.txt)的文档。

文档提供了一些python中字典使用的常见情况，当然在其他语言中也类似。

包括：
- passing keyword argument ：传参
- class method lookup：类方法查找
- instance attribute lookup and global variables：对象属性和全局变量查找
- builtins：内部自带
- uniquification：不是特别懂
- memebership Testing：成员检测，详情见[[Membership Testing]]
- dynamic mappings：动态mappings，很多删除中有一些添加和替换

文档详细分析了dict，在这里总结一些我觉得有价值的建议：

对于那些构建完成而不再改变的dict，我们可以将其转换为不可变数据结构，从而针对性地改善性能（例如禁用虚拟条目）

对于在相邻的查询中连续进行相同查询的情况，例如：
```python
dict['test'] = dict['test'] + 1
```
可以添加缓存改善性能

在不同的用例汇总，可以采用不同的策略针对性优化，如对于一次插入频繁读取的dict，他们可以将负载因子变小，加快查询速度。在比如对于预先知道dict大小的用例，我们可以之间创建一个目标大小的dict，而不是在负载满了之后再rehash。具体情况需要具体分析。

## 匹配DNA片段
在[[leetcode 187 重复的DNA序列]]中，我们已经讨论了在单个DNA片段中进行字符串匹配的算法。leetcode187使用的DNA片段不长，$1<len<10^5$。

ps04中则讨论在两段很长的DNA片段中，如果快速进行匹配。并讨论在不需要进行精确匹配时，如何在保证一定的精度的情况下加速计算。

### yield、懒加载与滑动窗口
该算法使用了迭代器实现了懒加载，而不是一次性加载和处理大量数据，降低了空间复杂度。python提供的yield关键字简化了迭代器的实现。

因为是采用迭代读取字符串，因此引入了滑动hash配合迭代器获取用于匹配的定长字符串。在滑动窗口中滚动计算字符串的hash值。

预先计算hash约束了dict的key的规模，这种策略在处理超大规模的数据时无法自动伸缩，反而会降低性能。但滚动hash又加速了每个string的hash的计算，提高了性能。

目前不清楚使用hash是否能够改善性能，因为最终的性能表现取决于上述两个约束的综合作用。可以肯定的是，就算能优化，也是同时间复杂度下的常数级性能优化。 #TODO

### DNA匹配结果的粗略统计
完整计算两段DNA片段的精确匹配很耗时。但如果只是统计和观察两段DNA的特征和相似程度，则可以通过采样法加速计算。

因为每隔1000个采样一次，因此滑动窗口法就不能用了，只计算提取的字符串的hash值。

为了直观地展示匹配的结果，将输出转换为图片。字符串匹配的结果是一个二维元祖，如(100,500)，可以解释为坐标，假设定义图片高为h，宽为w。每个像素就代表了二维空间中的一块区域。统计每个像素命中的次数，最后对所有像素做一次归一化，输出灰度图。

精确匹配结果（匹配所有字符串）
![](https://gitee.com/skytreedelivery/cloudimage/raw/master/img/output-1_final.png)

每间隔1000个核算采样一次
![](https://gitee.com/skytreedelivery/cloudimage/raw/master/img/output2_8_1000.png)

每间隔100000个核算采样一次
![](https://gitee.com/skytreedelivery/cloudimage/raw/master/img/output4_8_100000.png)

可以看出在每1000个核算采样一次的情况下，既保证了性能，也能给出粗略的可解读的结果。

而精确计算太慢，每100000个采样一次的结果不可解读。

### 代码实现

```python
#!/usr/bin/env python2.7

import unittest
from dnaseqlib import *

### Utility classes ###

# Maps integer keys to a set of arbitrary values.


class Multidict:
    # Initializes a new multi-value dictionary, and adds any key-value
    # 2-tuples in the iterable sequence pairs to the data structure.
    def __init__(self, pairs=[]):
        self.data = {}
        for pair in pairs:
            self.data.setdefault(pair[0], []).append(pair[1])

    # Associates the value v with the key k.
    def put(self, k, v):
        self.data.setdefault(k, []).append(v)
    # Gets any values that have been associated with the key k; or, if
    # none have been, returns an empty sequence.

    def get(self, k):
        if k in self.data:
            return self.data[k]
        return []

# Given a sequence of nucleotides, return all k-length subsequences
# and their hashes.  (What else do you need to know about each
# subsequence?)


def subsequenceHashes(seq, k):
    try:
        i = 0
        subSeq = ''
        while i < k:
            subSeq += seq.next()
            i += 1
        rh = RollingHash(subSeq)
        pos = 0
        while(True):
            yield (rh.current_hash(), (pos, subSeq))
            subSeq += seq.next()
            rh.slide(subSeq[0], subSeq[-1])
            subSeq = subSeq[1:]
            pos += 1
    except StopIteration:
        return

# Similar to subsequenceHashes(), but returns one k-length subsequence
# every m nucleotides.  (This will be useful when you try to use two
# whole data files.)


def intervalSubsequenceHashes(seq, k, m):
    try:
        pos = 0
        while True:
            subseq = ''
            for i in range(k):
                subseq += seq.next()
            rh = RollingHash(subseq)
            yield (rh.current_hash(), (pos, subseq))
            for i in range(m - k):
                seq.next()
            pos += m
    except StopIteration:
        return

# Searches for commonalities between sequences a and b by comparing
# subsequences of length k.  The sequences a and b should be iterators
# that return nucleotides.  The table is built by computing one hash
# every m nucleotides (for m >= k).


def getExactSubmatches(a, b, k, m):
    try:
        multiDict = Multidict(intervalSubsequenceHashes(a, k, m))
        for (hash, (b_pos, b_subseq)) in subsequenceHashes(b, k):
            for (a_pos, a_subseq) in multiDict.get(hash):
                if b_subseq != a_subseq:
                    continue
                yield (a_pos, b_pos)
    except StopIteration:
        return


if __name__ == '__main__':
    if len(sys.argv) != 4:
        print 'Usage: {0} [file_a.fa] [file_b.fa] [output.png]'.format(
            sys.argv[0])
        sys.exit(1)

    # The arguments are, in order: 1) Your getExactSubmatches
    # function, 2) the filename to which the image should be written,
    # 3) a tuple giving the width and height of the image, 4) the
    # filename of sequence A, 5) the filename of sequence B, 6) k, the
    # subsequence size, and 7) m, the sampling interval for sequence
    # A.
    compareSequences(getExactSubmatches,
                     sys.argv[3], (500, 500), sys.argv[1], sys.argv[2], 8, 1000
                     )
```
